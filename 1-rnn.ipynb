{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tight-investing",
   "metadata": {},
   "source": [
    "# LAB 9: Sentiment analysis using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nasty-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-acquisition",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjustable-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-explanation",
   "metadata": {},
   "source": [
    "Connect to the GPU (training RNNs without a GPU is veeery slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intensive-america",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA Tesla T4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-bikini",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "statutory-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"s3://ling583/sentiment.parquet\", storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rough-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"sentiment\"], random_state=619\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-culture",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Because every problem and every model is a little bit different, pytorch (unlike scikit-learn) doesn't have built-in `fit` and `predict` methods. We need to define them ourselves here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-contrast",
   "metadata": {},
   "source": [
    "This function gathers up a batch of training examples, encodes them, and sends them to the GPU for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accompanied-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a bunch of reviews, processes them in a way that torch can work with, then transfers\n",
    "# to the GPU for high speed computation.\n",
    "\n",
    "# Takes however many samples are to be in a mini-batch, packages them up as a tensor, \n",
    "# then sends them off to the GPU.\n",
    "def collate_batch(batch):\n",
    "    labels, texts = zip(*batch)\n",
    "    texts = [\n",
    "        [vocab[token] for token in [\"<s>\"] + tokenize(t) + [\"</s>\"]] for t in texts\n",
    "    ]\n",
    "    texts = [torch.tensor(t, dtype=torch.int64) for t in texts]\n",
    "    texts = pad_sequence(texts, padding_value=vocab[\"<pad>\"])\n",
    "    labels = torch.tensor([label_vocab[l] for l in labels], dtype=torch.int64)\n",
    "    return labels.to(device), texts.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-berkeley",
   "metadata": {},
   "source": [
    "This one applies the model to some test data, for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consolidated-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies of the decision and predict functions in scikit learn\n",
    "def decision_function(dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            results = []\n",
    "            for _, text in dataloader:\n",
    "                results.extend(model(text))\n",
    "    return results\n",
    "\n",
    "\n",
    "def predict(dataloader):\n",
    "    predicted = decision_function(dataloader)\n",
    "    return [label_vocab.itos[p.argmax()] for p in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-coaching",
   "metadata": {},
   "source": [
    "And this is the important part: the function that actually trains the model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "associate-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the training data, splits it into training and validation data, \n",
    "# sets them up for torch. 1 epoch is 1 pass over the training data.\n",
    "# During an epoch, apply the model to each batch, compute the error signal, and adjust the model to improve.\n",
    "# Finally print out the results\n",
    "\n",
    "def fit(epochs=5, batch_size=64, wd=None, clip=None):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if wd:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), weight_decay=wd)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "    t, v = train_test_split(train, test_size=0.1, stratify=train[\"sentiment\"])\n",
    "    train_dataset = list(zip(t[\"sentiment\"], t[\"text\"]))\n",
    "    valid_dataset = list(zip(v[\"sentiment\"], v[\"text\"]))\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        n = 0\n",
    "        for label, text in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                predicted = model(text)\n",
    "                loss = criterion(predicted, label)\n",
    "                correct += (predicted.argmax(1) == label).sum().item()\n",
    "                n += len(label)\n",
    "            scaler.scale(loss).backward()\n",
    "            if clip:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        train_acc = correct / n * 100.0\n",
    "        valid_pred = predict(valid_dataloader)\n",
    "        valid_acc = accuracy_score(v[\"sentiment\"], valid_pred) * 100.0\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch:2d} Time: {elapsed:6.3f}s \"\n",
    "            f\"Train acc: {train_acc:5.3f} Valid acc: {valid_acc:5.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-france",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Define the model class\n",
    "\n",
    "Okay, most of what's above is mostly [boilerplate](https://en.wikipedia.org/wiki/Boilerplate_code). Now we'll define the specific model and hyperparameter settings that we're using for this task.\n",
    "\n",
    "First, the model architecture. This is a basic [RNN](https://en.wikipedia.org/wiki/Recurrent_neural_network), using [GRU](https://en.wikipedia.org/wiki/Gated_recurrent_unit)s are the recurrent units.\n",
    "\n",
    "The hyperparameters of interest are:\n",
    "\n",
    "* `hidden_size` - Number of neurons in the hidden layer\n",
    "* `embedding_size` - Number of dimensions of hte lexical representations\n",
    "* `hidden_layers` - The number of layers in the model\n",
    "* `bidirectional` - If True, each hidden layer is actually 2 layers, one left-to-right and one right-to-left\n",
    "* `dropout` - On each update, disables some of the dimensions to make the model randomly break to force the training to work around it. Helps to prevent memorizations, but makes it hard to learn.\n",
    "\n",
    "Setting these higher makes the model more powerful and easier to train, but if you set them too high, it will remember the training data and just recall what the correct classification was while not being able to classify new texts.\n",
    "\n",
    "They control the ability of the model to learn details. Higher values for the first 3, plus setting `bidirectional` to `True`, increase the representational power of the model. That means it can learn more complex patterns and learn them more quickly. If these values are set too high, though, then the model can learn *too* well--it will simply memorize the training data and you'll get overfitting. The last value, dropout, helps control that. Higher values for `dropout` reduce the model's ability to learn and slow down training. The trick is finding a balance among all these settings that maximize learning while minimizing overfitting, which is unfortunately not easy to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "turned-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up the model\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab,\n",
    "        num_class,\n",
    "        hidden_size,\n",
    "        embedding_dim=128,\n",
    "        hidden_layers=1,\n",
    "        dropout=0.0,\n",
    "        bidirectional=True,\n",
    "    ):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        if not vocab.vectors is None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                vocab.vectors, freeze=True, padding_idx=vocab[\"<pad>\"]\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                len(vocab), embedding_dim, padding_idx=vocab[\"<pad>\"]\n",
    "            )\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.embedding.embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=hidden_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        out_size = hidden_size * hidden_layers\n",
    "        if bidirectional:\n",
    "            out_size = out_size * 2\n",
    "        self.fc = nn.Linear(out_size, num_class)\n",
    "\n",
    "    # applies the model\n",
    "    def forward(self, text, lengths=None):\n",
    "        embedded = self.embedding(text)\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        out = torch.cat(torch.unbind(hidden), axis=1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-department",
   "metadata": {},
   "source": [
    "Next we set up the vocabulary (this is the step performed by `CountVectorizer` in scikit-learn) using a [basic tokenizer](https://pytorch.org/text/stable/data_utils.html#get-tokenizer) that comes with pytorch. \n",
    "\n",
    "The \"specials\" are vocabulary items that don't correspond to words but are used internally by the model:\n",
    "\n",
    "* `<pad>` : For implementation reasons the documents in a batch all have to be the same length, so we add copies of the pseudo-word `<pad>` to the end of shorter reviews to make them as long as the longest one. \n",
    "* `<s>`, `</s>` : These mark the beginning and end of the reviews.\n",
    "* `<unk>` : Unknown words (i.e., words which are used in the test data that didn't get seen in the training data) get replaced with `<unk>`\n",
    "\n",
    "There's one adjustable parameter here: raising the value of `min_freq` removes low frequency lexical items (similar to `min_df` in scikit-learn). Increasing it usually doesn't improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informational-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9bfc48e80441b58fd5f7b0ae0d3b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenize = get_tokenizer(\"basic_english\")\n",
    "counter = Counter(concat(map(tokenize, tqdm(train[\"text\"]))))\n",
    "vocab = Vocab(\n",
    "    counter,\n",
    "    min_freq=1, # Change to limit the words brought into the vocab. Set as 1 brings in everything\n",
    "    specials=(\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"),\n",
    ")\n",
    "label_vocab = Vocab(Counter(train[\"sentiment\"]), specials=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-trustee",
   "metadata": {},
   "source": [
    "Now we instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "broken-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model and send it off to the GPU\n",
    "# generally start with a model that overfits\n",
    "model = TextClassificationModel(\n",
    "    vocab,\n",
    "    len(label_vocab),\n",
    "    hidden_size=256, # this is a high value for this parameter\n",
    "    embedding_dim=128,\n",
    "    hidden_layers=2,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True,\n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-criminal",
   "metadata": {},
   "source": [
    "And finally, we train! There are three important settings here:\n",
    "\n",
    "* `epochs` : This is the number of passes over the training data that we make when fitting the model. A crude way to avoid overfitting is to reduce this, which stops before training before the model has converged.\n",
    "* `batch_size` : This is the number of reviews that get processed at once during training. In general, increasing `batch_size` makes the program run faster (since it lets us take better advantage of the GPU) but may require more epochs to converge. Setting `batch_size` too high can overload the GPUs memory and lead to a crash. The effects of changing `batch_size` on the final results are hard to predict, but it can make a big difference.\n",
    "* `wd` : This is the \"[weight decay](https://www.fast.ai/2018/07/02/adam-weight-decay/)\" parameter. Setting this to a value other than `None` regularizes the model and can reduce overfitting (similar to setting `alpha` for `SGDClassifier`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "large-insider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382370550fba4d2fb55fc3776421dc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Time: 69.758s Train acc: 97.608 Valid acc: 97.700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ce80531e9b47b683638879e39c7fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Time: 68.997s Train acc: 99.097 Valid acc: 97.425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b030b7744713409db4cffed9dc91ee6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Time: 70.270s Train acc: 98.367 Valid acc: 96.475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70836b1bf3dd45e38ba109ffb429b208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Time: 69.193s Train acc: 99.608 Valid acc: 96.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60598e81e1bb4dbfa239a8e1d380f72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Time: 70.146s Train acc: 99.611 Valid acc: 96.525\n"
     ]
    }
   ],
   "source": [
    "fit(epochs=5, batch_size=64, wd=None)\n",
    "# We can see over time that this model overfits. This is represented by the fact that the training accuracy\n",
    "# continues to go up while the validation accuracy eventually plateaus and then decreases. \n",
    "# This shows that the model is slowly memorizing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "changed-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.670 F1 = 85.883\n"
     ]
    }
   ],
   "source": [
    "test_dataset = list(zip(test[\"sentiment\"], test[\"text\"]))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test_predicted = predict(test_dataloader)\n",
    "acc = 100 * accuracy_score(test[\"sentiment\"], test_predicted)\n",
    "f1 = 100 * f1_score(test[\"sentiment\"], test_predicted, average=\"macro\")\n",
    "print(f\"Accuracy = {acc:.3f} F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-fifth",
   "metadata": {},
   "source": [
    "## Try changing some parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expanded-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a value for dropout\n",
    "model = TextClassificationModel(\n",
    "    vocab,\n",
    "    len(label_vocab),\n",
    "    hidden_size=256,\n",
    "    embedding_dim=128,\n",
    "    hidden_layers=2,\n",
    "    dropout=0.5, # after each pass, half of the model receives adjustments\n",
    "    bidirectional=True,\n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "persistent-pressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b2167bebb444b7a2e48fd9e69a3e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Time: 85.304s Train acc: 78.564 Valid acc: 86.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba40ecf5e41c4a888a5f389c5aece845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Time: 84.621s Train acc: 89.447 Valid acc: 88.950\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b01cd77d8e54aa3aa187394bed11ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Time: 86.635s Train acc: 92.192 Valid acc: 89.500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0293d2702de401d839fd85b8eda86ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Time: 86.045s Train acc: 94.144 Valid acc: 90.250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c7aea9720c426eb3dfa84ff8684759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Time: 85.360s Train acc: 96.058 Valid acc: 90.175\n"
     ]
    }
   ],
   "source": [
    "fit(epochs=5, batch_size=64, wd=None)\n",
    "# There is still some overfitting, but its not as bad\n",
    "# Note that the highest validation accuracy is at 4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "committed-founder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90.010 F1 = 87.360\n"
     ]
    }
   ],
   "source": [
    "test_dataset = list(zip(test[\"sentiment\"], test[\"text\"]))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test_predicted = predict(test_dataloader)\n",
    "acc = 100 * accuracy_score(test[\"sentiment\"], test_predicted)\n",
    "f1 = 100 * f1_score(test[\"sentiment\"], test_predicted, average=\"macro\")\n",
    "print(f\"Accuracy = {acc:.3f} F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "roman-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cc953838a54f13a64256b8b4918323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Time: 84.074s Train acc: 96.542 Valid acc: 95.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79747ef26c854407951efab84208ef5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Time: 86.187s Train acc: 97.514 Valid acc: 95.725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b597a8aba7d24e26876026064ff564e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Time: 86.086s Train acc: 97.978 Valid acc: 95.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f30eabd84f5499cbd912e991f6d99da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Time: 86.479s Train acc: 98.569 Valid acc: 95.600\n"
     ]
    }
   ],
   "source": [
    "# Reduce the epochs to 4\n",
    "# Note the very high training accuracy. This is because we did not reset the model, so instead of running \n",
    "# just 4 epochs on a new model, we ran 4 additional epochs on top of the first % 5, overfitting even more.\n",
    "fit(epochs=4, batch_size=64, wd=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "remarkable-helena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.950 F1 = 86.707\n"
     ]
    }
   ],
   "source": [
    "test_dataset = list(zip(test[\"sentiment\"], test[\"text\"]))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test_predicted = predict(test_dataloader)\n",
    "acc = 100 * accuracy_score(test[\"sentiment\"], test_predicted)\n",
    "f1 = 100 * f1_score(test[\"sentiment\"], test_predicted, average=\"macro\")\n",
    "print(f\"Accuracy = {acc:.3f} F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nuclear-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the model again\n",
    "model = TextClassificationModel(\n",
    "    vocab,\n",
    "    len(label_vocab),\n",
    "    hidden_size=256,\n",
    "    embedding_dim=128,\n",
    "    hidden_layers=2,\n",
    "    dropout=0.5, # after each pass, half of the model receives adjustments\n",
    "    bidirectional=True,\n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vietnamese-avatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f74787ec232497eb53164203a4a2668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Time: 84.085s Train acc: 78.200 Valid acc: 88.750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cfc0025a6c43cab7baae6addd30232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Time: 85.602s Train acc: 89.669 Valid acc: 90.750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c9bbf3c581483f98f7aa19c489cc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Time: 85.711s Train acc: 92.153 Valid acc: 91.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9295359c4435414480fb972c2f30e712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Time: 85.805s Train acc: 93.992 Valid acc: 90.600\n"
     ]
    }
   ],
   "source": [
    "# Run for 4 epochs from scratch \n",
    "fit(epochs=4, batch_size=64, wd=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hollywood-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90.490 F1 = 87.328\n"
     ]
    }
   ],
   "source": [
    "test_dataset = list(zip(test[\"sentiment\"], test[\"text\"]))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test_predicted = predict(test_dataloader)\n",
    "acc = 100 * accuracy_score(test[\"sentiment\"], test_predicted)\n",
    "f1 = 100 * f1_score(test[\"sentiment\"], test_predicted, average=\"macro\")\n",
    "print(f\"Accuracy = {acc:.3f} F1 = {f1:.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder that this is our vocab, just copied from above\n",
    "# Go ahead and reinitialize it\n",
    "tokenize = get_tokenizer(\"basic_english\")\n",
    "counter = Counter(concat(map(tokenize, tqdm(train[\"text\"]))))\n",
    "vocab = Vocab(\n",
    "    counter,\n",
    "    min_freq=1, # Change to limit the words brought into the vocab. Set as 1 brings in everything\n",
    "    specials=(\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"),\n",
    ")\n",
    "label_vocab = Vocab(Counter(train[\"sentiment\"]), specials=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "religious-donor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:21<00:00, 18979.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Modify the vocab with preestablished word vectors\n",
    "vocab.load_vectors(\"glove.6B.200d\", unk_init = lambda t: torch.nn.init.uniform_(t, -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sunset-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the model again\n",
    "model = TextClassificationModel(\n",
    "    vocab,\n",
    "    len(label_vocab),\n",
    "    hidden_size=256,\n",
    "    embedding_dim=128, # this will be ignored and will instead use dimensions from the modified vocab\n",
    "    hidden_layers=2,\n",
    "    dropout=0.5, # after each pass, half of the model receives adjustments\n",
    "    bidirectional=True,\n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "round-injection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54313e0b4e1e44fdac1f954983bec35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Time: 84.296s Train acc: 81.661 Valid acc: 88.425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398a17285eb845bfbca82b797146e760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Time: 84.562s Train acc: 88.453 Valid acc: 89.750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3734f172f80e4b1fb538d4ca58a5ac94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Time: 85.100s Train acc: 90.000 Valid acc: 90.150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887e83d9f5c34bcda42d1e2e2ce277f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Time: 84.386s Train acc: 91.289 Valid acc: 89.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947c9afa330b435eaf6b14f6271b749d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Time: 86.261s Train acc: 92.267 Valid acc: 89.400\n"
     ]
    }
   ],
   "source": [
    "# Run for 4 epochs from scratch \n",
    "fit(epochs=5, batch_size=64, wd=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "executive-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.950 F1 = 87.278\n"
     ]
    }
   ],
   "source": [
    "test_dataset = list(zip(test[\"sentiment\"], test[\"text\"]))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test_predicted = predict(test_dataloader)\n",
    "acc = 100 * accuracy_score(test[\"sentiment\"], test_predicted)\n",
    "f1 = 100 * f1_score(test[\"sentiment\"], test_predicted, average=\"macro\")\n",
    "print(f\"Accuracy = {acc:.3f} F1 = {f1:.3f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-recall",
   "metadata": {},
   "source": [
    "## Try to get accuracy above 91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-anthony",
   "metadata": {},
   "source": [
    "## Changelog (reordered from best to worst by accuracy):\n",
    "Parameters listed in order of hidden_size, embedding_dim, hidden_layers, dropout, bidirectional, epochs\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, **dropout=0.25**, bidirectional=True, epochs=5  \n",
    "Accuracy = 90.750 F1 = 87.642\n",
    "\n",
    "hidden_size=256, embedding_dim=128, **hidden_layers=3**, dropout=0.25, bidirectional=True, epochs=5  \n",
    "Accuracy = 90.470 F1 = 87.716\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, **dropout=0.3**, bidirectional=True, epochs=6  \n",
    "Accuracy = 90.310 F1 = 87.626\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=3, **dropout=0.6**, bidirectional=True, epochs=5  \n",
    "Accuracy = 90.290 F1 = 87.656\n",
    "\n",
    "hidden_size=256, embedding_dim=128, **hidden_layers=2**, **dropout=0.6**, bidirectional=True, epochs=5  \n",
    "Accuracy = 90.280 F1 = 87.671\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, **dropout=0.2**, bidirectional=True, epochs=5  \n",
    "Accuracy = 90.200 F1 = 87.019\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, **dropout=0.75**, bidirectional=True, epochs=5  \n",
    "Accuracy = 89.920 F1 = 85.974\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, dropout=0.25, bidirectional=True, **epochs=6**  \n",
    "Accuracy = 89.500 F1 = 85.966\n",
    "\n",
    "#### Reset vocab and introduce the new dimensions\n",
    "\n",
    "hidden_size=256, embedding_dim=128, **hidden_layers=3**, **dropout=0.5**, bidirectional=True, epochs=5  \n",
    "Accuracy = 90.190 F1 = 87.518\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, dropout=0.5, bidirectional=True, epochs=5  \n",
    "Accuracy = 89.950 F1 = 87.278\n",
    "    \n",
    "hidden_size=256, embedding_dim=128, hidden_layers=2, **dropout=0.25**, bidirectional=True, epochs=5  \n",
    "Accuracy = 89.560 F1 = 86.031\n",
    "\n",
    "hidden_size=256, embedding_dim=128, hidden_layers=3, **dropout=0.6**, bidirectional=True, epochs=5  \n",
    "Accuracy = 87.220 F1 = 84.941\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "annoying-moderator",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-53068f3c8edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reset the model again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = TextClassificationModel(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "# Reset the model again\n",
    "model = TextClassificationModel(\n",
    "    vocab,\n",
    "    len(label_vocab),\n",
    "    hidden_size=256,\n",
    "    embedding_dim=128, # this will be ignored and will instead use dimensions from the modified vocab\n",
    "    hidden_layers=2,\n",
    "    dropout=0.5, # after each pass, half of the model receives adjustments\n",
    "    bidirectional=True,\n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "laden-stylus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb680966d0cb45959d00ab739a8f06b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-6a535238ddbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-eeb89c8d1deb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, batch_size, wd, clip)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-0f4372415d83>\u001b[0m in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "fit(epochs=5, batch_size=64, wd=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = list(zip(test[\"sentiment\"], test[\"text\"]))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "test_predicted = predict(test_dataloader)\n",
    "acc = 100 * accuracy_score(test[\"sentiment\"], test_predicted)\n",
    "f1 = 100 * f1_score(test[\"sentiment\"], test_predicted, average=\"macro\")\n",
    "print(f\"Accuracy = {acc:.3f} F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ordered-works",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8694fbc71ebb41f395034f879685a9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reminder that this is our vocab, just copied from above\n",
    "# Go ahead and reinitialize it\n",
    "tokenize = get_tokenizer(\"basic_english\")\n",
    "counter = Counter(concat(map(tokenize, tqdm(train[\"text\"]))))\n",
    "vocab = Vocab(\n",
    "    counter,\n",
    "    min_freq=1, # Change to limit the words brought into the vocab. Set as 1 brings in everything\n",
    "    specials=(\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"),\n",
    ")\n",
    "label_vocab = Vocab(Counter(train[\"sentiment\"]), specials=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "labeled-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the vocab with preestablished word vectors\n",
    "vocab.load_vectors(\"glove.6B.200d\", unk_init = lambda t: torch.nn.init.uniform_(t, -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-hebrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lovely-result",
   "metadata": {},
   "source": [
    "# make sure to shut down this kernel before running distilbert, otherwise will run out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
